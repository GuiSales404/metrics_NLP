# -*- coding: utf-8 -*-
"""awsMetrics.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IuS4EKVQAFtL0eIiajPxsNHXeh0cjWk_
"""

!pip install transformers datasets jiwer torchaudio soundfile
!pip install gensim==3.8.0
!apt uptdade

import torchaudio
from datasets import load_metric
from transformers import (Wav2Vec2ForCTC, Wav2Vec2Processor,)
import torch
import re
import pandas as pd

!pip install nltk 
from gensim import corpora
from gensim.matutils import softcossim
import nltk
from nltk.translate import bleu_score, meteor_score
from datasets import load_metric
wer = load_metric("wer")
from gensim.models import KeyedVectors


def clean_str(x):
    return re.sub('\W', ' ', x).lower()


def cosine_similarity(reference, hypothesis, model):
    reference = reference.split()
    hypotesis = hypothesis.split()
    documents = [hypotesis, reference]
    dictionary = corpora.Dictionary(documents)

    similarity_matrix = emb_models[model].similarity_matrix(dictionary)

    hypotesis = dictionary.doc2bow(hypotesis)
    reference = dictionary.doc2bow(reference)

    return softcossim(hypotesis, reference, similarity_matrix)


def bleu(reference, hypothesis):
    references = [reference.split()]
    hypothesis = hypothesis.split()

    if len(references[0]) == 1:
        weights=(1.0, 0.0, 0.0, 0.0)
    elif len(references[0]) == 2:
        weights=(0.5, 0.5, 0.0, 0.0)
    elif len(references[0]) == 3:
        weights=(0.4, 0.3, 0.3, 0.0)
    else:
        weights=(0.4, 0.3, 0.2, 0.1)

    return bleu_score.sentence_bleu(references, hypothesis, weights=weights)


pt_stemmer = nltk.stem.RSLPStemmer()
def meteor(reference, hypothesis):
    references = [reference.split()]
    # references = [word for word in references if word != '']
    hypothesis = hypothesis.split()
    return meteor_score.meteor_score(references, hypothesis, stemmer=pt_stemmer)

emb_models = {
        'word2vec_cbow_s50': KeyedVectors.load_word2vec_format('JIDM/embeddings/cbow_s50.txt'),
        'word2vec_skip_s50': KeyedVectors.load_word2vec_format('JIDM/embeddings/skip_s50.txt')
    }

def run_wav2vec2(path_csv=None, separator='|', save=False, output_to_save=None):
    dataset = pd.read_csv(path_csv, sep=separator)
    dataset.dropna(inplace=True)
    print(dataset.shape)
    
    ds = dataset.apply(map_to_array, axis=1)
    result = ds.apply(map_to_pred, axis=1)
    result = result[['file','sentence', 'translation','gender']]
    
    if save:
        name = 'transcribed_w2v2.tsv'
        result.to_csv(output_to_save+name, sep='\t', index=False)
        
    return result


def get_metrics(result, save=True, output_to_save=None):
    originals = result["sentence"]
    sentences = result["sentence"].apply(clean_str)
    translations = result["translation"].apply(clean_str)

    # Cossine metrics
    for model in emb_models:
        print(f'Applying for {model}')
        for original, sentence, translation in zip(originals, sentences, translations):
            sentence = clean_str(sentence)
            translation = clean_str(translation)
            result.loc[result['sentence'] == original, f"cos_sim_{model}"] = cosine_similarity(sentence, translation, model)

    for original, sentence, translation in zip(originals, sentences, translations):
        sentence = clean_str(sentence)
        translation = clean_str(translation)
        result.loc[result['sentence'] == original, 'bleu'] = bleu(sentence, translation)
        result.loc[result['sentence'] == original, 'meteor'] = meteor(sentence, translation)

    
    print(f'WER: {wer.compute(predictions=translations, references=sentences)*100}')
    print(f'bleu: {result["bleu"].mean()}')
    print(f'meteor: {result["meteor"].mean()}')
    for model in emb_models:
        print(f'{model}: {result[f"cos_sim_{model}"].mean()}')

    if save:
        result.to_csv(output_to_save+'/transcribed_w2v2_metrics.tsv', sep='\t', index=False)

